{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using network analysis to efficiently spread data awareness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently heard the wonderful story of how last year, Marks & Spencer launched a data academy to train staff across all parts of the business in data science - HR, Finance, IT, Sales and Operations, Logistics... After an intensive 18-month in-work data skills programme, these staff became data ambassadors for their business areas and local teams so that the effect could spread through the staff network. While it is unlikely that everyone at M&S will become a fully fledged data scientist overnight, the organisation as a whole is now far more data-oriented. For example, HR analyse data to identify staff who might be thinking of leaving; Sales, Operations and Logistics use data to work out how to reduce costs and streamline customer delivery. Importantly, staff ask questions in a data-oriented way and seek to support their decisions with evidence.\n",
    "\n",
    "Inspired by this, I have as one of my ambitions to make my organisation data aware. I don't mean just have awesome data science teams developing cool new products and services (although I hope we will do this too), but rather have everyone in the organisation feel comfortable asking for data to make the best-informed decisions they can.\n",
    "\n",
    "Being new to the organisation though, I was wondering how I might go about doing this. During my first month, my line manager introduced me to several key individuals who were invested in data in some way, either because they were trying to develop data-driven products and services, or because they were using data analyses to make decisions. Through these individuals, I got to know more and more people who had a love for data. I started to compile a list of these data fans and pondered how quickly we might be able to spread this awareness through the organisation.\n",
    "\n",
    "I decided to get hold of the data behind the organisational chart with all staff's job titles, departments, line managers, functions, etc. so that I could get a feel for the organisation's structure and staff's interests. Then I ran some simple network analyses to help me spread data awareness across the organisation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'AnonymisedStaff.csv'\n",
    "#fname = 'anon_staffdata.csv'\n",
    "allstaffdata = pd.read_csv(fname, encoding = \"ISO-8859-1\")\n",
    "colTypes = {'ID': str, 'Department': str, 'Manager': str, 'Location': str, 'DataFan': str}\n",
    "#colTypes = {'Preferred Name': str, 'Business Unit': str, 'Line Manager': str, 'Location': str, 'DataFan': str}\n",
    "\n",
    "allstaffdata = pd.read_csv(fname, encoding = \"ISO-8859-1\", dtype = colTypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstaffdata.columns\n",
    "allstaffdata.head()\n",
    "## For anonymised data:\n",
    "department = 'Department'\n",
    "identifier = 'ID' \n",
    "manager = 'Manager'\n",
    "location = 'Location'\n",
    "\n",
    "#department = 'Business Unit'\n",
    "#identifier = 'Preferred Name'\n",
    "#manager = 'Line Manager'\n",
    "#location = 'Location'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the data staff?\n",
    "* Which departments?\n",
    "* Which company locations?\n",
    "* Which teams (indicated by line managers)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "staffdata = allstaffdata\n",
    "\n",
    "datafans = staffdata[staffdata['DataFan']=='yes']\n",
    "#List of departments covered by data fans\n",
    "DFDepartments = np.unique(datafans[[department]])\n",
    "Departments = np.unique(staffdata[[department]])\n",
    "#List of locations covered by data fans\n",
    "DFLocations = np.unique(datafans[[location]])\n",
    "Locations = np.unique(staffdata[[location]])\n",
    "#List of data fan line managers\n",
    "DFManagers = np.unique(datafans[[manager]])\n",
    "Managers = np.unique(staffdata[[manager]])\n",
    "\n",
    "print('#Data fans: {}'.format(len(datafans)))\n",
    "\n",
    "#Coverage of data fans:\n",
    "print('#Departments covered by data fans: {} out of {}'.format(len(DFDepartments), len(Departments)))\n",
    "print('#staff covered: {} out of {}\\n'.format(len(staffdata[staffdata[department].isin(DFDepartments)]), len(staffdata)))\n",
    "print(DFDepartments)\n",
    "print('#Locations covered by data fans: {} out of {}'.format(len(DFLocations), len(Locations)))\n",
    "print('#staff covered: {} out of {}\\n'.format(len(staffdata[staffdata[location].isin(DFLocations)]), len(staffdata)))\n",
    "print(DFLocations)\n",
    "print('#Managers covered by data fans: {} out of {}'.format(len(DFManagers), len(Managers)))\n",
    "print('#staff covered: {} out of {}\\n'.format(len(staffdata[staffdata[manager].isin(DFManagers)]), len(staffdata)))\n",
    "print(DFManagers)\n",
    "\n",
    "#Identify more susceptible staff members in terms of sharing the same departments, locations or teams as existing fans.\n",
    "staffdata['PotentialDepartmentDataFan'] = np.where(staffdata[department].isin(DFDepartments), 'yes', 'no')\n",
    "staffdata['PotentialLocationDataFan'] = np.where(staffdata[location].isin(DFLocations), 'yes', 'no')\n",
    "staffdata['PotentialManagerDataFan'] = np.where(staffdata[manager].isin(DFManagers), 'yes', 'no')\n",
    "\n",
    "staffdata[staffdata[identifier].isin(datafans[[identifier]])]['PotentialLocationDataFan'] = 'yes'\n",
    "staffdata[staffdata[identifier].isin(datafans[[identifier]])]['PotentialDepartmentDataFan'] = 'yes'\n",
    "staffdata[staffdata[identifier].isin(datafans[[identifier]])]['PotentialManagerDataFan'] = 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Data fans in the staff network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "#https://plot.ly/python/igraph-networkx-comparison/ (Comparison of two of the main Python network libraries.)\n",
    "\n",
    "#The line management network\n",
    "G = nx.convert_matrix.from_pandas_edgelist(staffdata, source=manager, target=identifier, \n",
    "                                           create_using=nx.DiGraph)\n",
    "edges = pd.DataFrame({'target' : staffdata[identifier],\n",
    "                      'source' : staffdata[manager]})\n",
    "\n",
    "nodes = pd.DataFrame({'node' : staffdata[identifier],\n",
    "                      'name' : staffdata[identifier],\n",
    "                      'Department' : staffdata[department],\n",
    "                      'Manager': staffdata[manager],\n",
    "                      'Location' : staffdata[location],\n",
    "                      'DataFan': staffdata['DataFan'],\n",
    "                     'PotentialDepartmentDataFan': staffdata['PotentialDepartmentDataFan'],\n",
    "                     'PotentialLocationDataFan': staffdata['PotentialLocationDataFan'],\n",
    "                     'PotentialManagerDataFan': staffdata['PotentialManagerDataFan']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the team network - management as proxy for connections between individuals (team membership). \n",
    "#Two employees are connected if they share the same line manager.\n",
    "#Get the list of managers (teams)\n",
    "from itertools import permutations, chain\n",
    "\n",
    "managers = staffdata[manager].unique()\n",
    "manager_teams = {};\n",
    "for mgr in managers:\n",
    "    manager_teams[mgr] = staffdata[staffdata[manager]== mgr][identifier].tolist()\n",
    "\n",
    "team_links = [list(permutations(team, 2)) for team in manager_teams.values()] \n",
    "team_links = list(chain(*team_links))\n",
    "G.add_edges_from(team_links) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some centrality measures\n",
    "d = nx.degree(G)\n",
    "c = nx.degree_centrality(G)\n",
    "b = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## NB there are some managers who are in the graph but not in staffdata because they are externals, so\n",
    "##there are a greater number of nodes in G than there are records in staffdata.\n",
    "\n",
    "degreesdict = {name:degree for name, degree in d}\n",
    "\n",
    "degrees = pd.DataFrame.from_dict(degreesdict, orient='index')\n",
    "centralities = pd.DataFrame.from_dict(c, orient='index')\n",
    "betweenness = pd.DataFrame.from_dict(b, orient='index')\n",
    "degrees.columns = ['Degree']\n",
    "centralities.columns = ['DegreeCentrality']\n",
    "betweenness.columns = ['BetweennessCentrality']\n",
    "print(degrees.sort_values(by='Degree', ascending=False).head(20))\n",
    "print(centralities.sort_values(by='DegreeCentrality', ascending=False).head(20))\n",
    "print(betweenness.sort_values(by='BetweennessCentrality', ascending=False).head(20))\n",
    "\n",
    "datafannames = datafans[identifier].tolist()\n",
    "fandegrees = degrees[degrees.index.isin(datafannames)]\n",
    "fancentralities = centralities[centralities.index.isin(datafannames)]\n",
    "fanbetweenness = betweenness[betweenness.index.isin(datafannames)]\n",
    "\n",
    "print(fandegrees.sort_values(by='Degree', ascending=False).head())\n",
    "print(fancentralities.sort_values(by='DegreeCentrality', ascending=False).head())\n",
    "print(fanbetweenness.sort_values(by='BetweennessCentrality', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join degrees data to other data\n",
    "staffdata = staffdata.merge(degrees, left_on=identifier, right_on=degrees.index)\n",
    "staffdata = staffdata.merge(centralities, left_on=identifier, right_on=degrees.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetricHist(df, colname='Degree'):\n",
    "    \n",
    "    data = [go.Histogram(x=df[colname])]\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(\n",
    "            #type='log',\n",
    "            autorange=True\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            #type='log',\n",
    "            autorange=True\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotMetricHist(staffdata, 'Degree')\n",
    "plotMetricHist(staffdata, 'DegreeCentrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staffdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drawnetwork(staffdata=staffdata, field='DataFan', d=d, dthreshold=2, sizefield='Degree', \n",
    "                sizemultiplier=3, G=G):\n",
    "    \n",
    "    #Formatting settings\n",
    "    #Set colour mappings to field    \n",
    "    flist = staffdata[field].unique()\n",
    "    numcolours = len(flist)\n",
    "    colours = sns.color_palette(\"hls\", numcolours)\n",
    "    colourmappings = dict(zip(flist, colours))\n",
    "    \n",
    "    #Filtering by degree\n",
    "    #Remove nodes with degree (d) below threshold (dthreshold)\n",
    "    selected_nodes = [n for n in nodes.name if d[n] > dthreshold]\n",
    "    plotgraph = G.subgraph(selected_nodes)\n",
    "    \n",
    "    # Set node positions\n",
    "    pos = nx.spring_layout(plotgraph, seed=0)\n",
    "    for node in plotgraph.nodes():\n",
    "        plotgraph.node[node]['pos']= pos[node]\n",
    "        \n",
    "    # Set other node attributes\n",
    "    excluded = []\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    textlist = []\n",
    "    sizelist = []\n",
    "    namelist = []\n",
    "    colourlist = []\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for node in plotgraph.nodes():\n",
    "       \n",
    "    \n",
    "        try:\n",
    "            \n",
    "        \n",
    "            f = nodes[nodes['name']==node][field].values[0]\n",
    "        \n",
    "            x, y = plotgraph.node[node]['pos']\n",
    "            xlist.append(x)\n",
    "            ylist.append(y)\n",
    "            \n",
    "            ## Add node labels for hover over text\n",
    "            text = node + ' <br>#connections: ' + str(d[node])\n",
    "            textlist.append(text)\n",
    "            \n",
    "            ## Size the node depending on sizefield and sizemultiplier\n",
    "            if sizefield=='':\n",
    "                size = 1;\n",
    "            else:\n",
    "                size = staffdata[staffdata[identifier]==node][sizefield].values[0]\n",
    "            sizelist.append(size * sizemultiplier)\n",
    "            \n",
    "            ## Map the colours to the nodes depending on the field values\n",
    "            fcolour = 'rgba({}, {}, {}, {})'.format(colourmappings[f][0], colourmappings[f][1], colourmappings[f][2], .8)    \n",
    "            colourlist.append(fcolour)\n",
    "    \n",
    "        except:\n",
    "            excluded.append(node)\n",
    "        \n",
    "    print('Number of nodes excluded because {} not given: {}\\n'.format(field, len(excluded)))\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    ## Create the visualisation\n",
    "    xlistedge =[]\n",
    "    ylistedge = []\n",
    "    \n",
    "    for edge in plotgraph.edges():\n",
    "        x0, y0 = plotgraph.node[edge[0]]['pos']\n",
    "        x1, y1 = plotgraph.node[edge[1]]['pos']\n",
    "        xlistedge += [x0, x1, None]\n",
    "        ylistedge += [y0, y1, None]        \n",
    "        \n",
    "    # Create edge trace:\n",
    "    edge_trace = go.Scatter(x = xlistedge, y = ylistedge, text = textlist,\n",
    "                    line = go.scatter.Line(width = 0.5, color = '#888'),\n",
    "                    mode = 'lines', hoverinfo = 'none')\n",
    "    \n",
    "    # Create node trace:\n",
    "    node_trace = go.Scatter(x = xlist, y = ylist, text = textlist, mode = 'markers',\n",
    "                    hoverinfo='text',\n",
    "                    marker = go.scatter.Marker(\n",
    "                    color = colourlist,\n",
    "                    size = sizelist,\n",
    "                    line = dict(color='rgb(50,50,50)', width=0.5)))\n",
    "\n",
    "\n",
    "    data=[node_trace, edge_trace]\n",
    "    layout = go.Layout(title=field, \n",
    "                   showlegend=False, \n",
    "                   xaxis=dict(\n",
    "                   autorange=True,\n",
    "                   showgrid=False,\n",
    "                   zeroline=False,\n",
    "                   showline=False,\n",
    "                   ticks='',\n",
    "                   showticklabels=False),\n",
    "            yaxis=dict(\n",
    "                autorange=True,\n",
    "                showgrid=False,\n",
    "                zeroline=False,\n",
    "                showline=False,\n",
    "                ticks='',\n",
    "                showticklabels=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig, filename='Staff network')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawnetwork(sizefield='')\n",
    "drawnetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Marketing Decisions based on network analysis\n",
    "\n",
    "We can use very simple network analyses to decide how best to use our data fans to spread the message. For example, we can compare the networks that would result if they spread the message to staff in their departments vs. focusing on staff in their location vs. spreading to their team (as indicated by shared managers).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show what might happen over time:\n",
    "\n",
    "def networkevolution(df=staffdata, numsteps=3, transfield=department, infectfield='DataFan'):\n",
    "    \n",
    "    network = df.copy(deep=True)\n",
    "    print('Network evolution over {} time steps based on shared {}s: '.format(numsteps, transfield))\n",
    "    \n",
    "    \n",
    "    for i in range(0, numsteps):\n",
    "        drawnetwork(staffdata=network, field=infectfield)\n",
    "        \n",
    "        infected = network[network[infectfield]=='yes']\n",
    "        \n",
    "        #List of field values covered by infected\n",
    "        infectedVals = np.unique(infected[[transfield]])\n",
    "        vals = np.unique(network[[transfield]])\n",
    "        \n",
    "        print('#{}s covered by infected: {} out of {}'.format(transfield, len(infectedVals), len(vals)))\n",
    "        print('#staff infected: {} out of {} at t {}'.format(len(infected), len(network), i))\n",
    "        \n",
    "        print(infectedVals)\n",
    "        \n",
    "        network['next'] = np.where(network[transfield].isin(infectedVals), 'yes', 'no')\n",
    "        print('#staff next infected: {} out of {}'.format(len(network[network['next']=='yes']), len(network)))\n",
    "        \n",
    "        #List of field values covered by infected\n",
    "        infectedVals = np.unique(infected[[transfield]])\n",
    "        vals = np.unique(network[[transfield]])\n",
    "        \n",
    "    \n",
    "        network[network[identifier].isin(infected[identifier].values)]['next'] = 'yes'\n",
    "        #If the field is also a member of staff (e.g. manager), then they also need to be infected.\n",
    "        network[network[identifier].isin(infectedVals)]['next'] = 'yes'\n",
    "        \n",
    "        network.loc[:, infectfield] = network['next'].values\n",
    "        print('Check reset: {}\\n'.format(network[infectfield].equals(network['next'])))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "networkevolution(transfield=department)\n",
    "networkevolution(transfield=manager)\n",
    "networkevolution(transfield=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these networks, we can see that spreading simply by the teams (as indicated by shared managers) results in a far lower rate of spread (only 180 out of 3358) than either location (coverage 2057 out of 3358) or department (coverage 2892 out of 3358). \n",
    "\n",
    "Of course, in practice this does not tell us much since these networks only show what happens in the limit, e.g. they show they that if spreading only by team, our message would only reach 180 out of 3358 even if we had inifinite time, while if spreading by department with infnite time, we could reach 2892 out of 3358. \n",
    "\n",
    "Perhaps more usefully, we should find a way to decide who should be targeted next for the message to spread most efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who should I target next?\n",
    "There is no one correct answer to this, and it is a topic that is much discussed and contested in Marketing,  Communications and Sales. \n",
    "\n",
    "Some strategies are:\n",
    "* Finding nodes in the network that already have neighours or nodes in close proximity that are 'converted'. In this case, I might look for individuals who are in the same team (line-managed by the same people), same country, and/or same business unit. \n",
    "* Finding nodes in the network that are most 'influential'. In this case, I might look for individuals who line manage a lot of people or who have line managers or subordinates who belong to a large number of business units or span many geographical locations.\n",
    "\n",
    "I could also create a metric that combines both of the above and target the ones who score most highly. By doing this, I am choosing individuals who are both more likely to be receptive to data awareness and who are able to raise awareness in a greater number of other individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top x most connected individuals\n",
    "numtop = 20\n",
    "sortdegrees = staffdata.sort_values(by='Degree', ascending=False)\n",
    "print(sortdegrees.head(numtop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many disconnected networks are there (in terms of the management structure)?\n",
    "It is useful to know how many disconnected networks there are so that 'islands' can be targeted separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = list(nx.weakly_connected_component_subgraphs(G))\n",
    "print('#Distinct staff networks: {}\\n'.format(len(subgraphs)))\n",
    "subgraphsizes = [nx.number_of_nodes(subgraphs[i]) for i in range(0, len(subgraphs))]\n",
    "print(subgraphsizes)\n",
    "\n",
    "# Draw the two largest subgraphs\n",
    "drawnetwork(field='DataFan', G=subgraphs[0])\n",
    "drawnetwork(field='DataFan', G=subgraphs[1], dthreshold=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in terms of management structure there are 44 disconnected subnetworks in the staff network, this does not necessarily mean that these truly represent isolated groups of staff, only that formally speaking, they are not connected to each other via management. The vast majority of staff belong to the larest component (containing 3092, with the next larest only containing 22, see output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If only I had more data (and more hours in the day)...\n",
    "\n",
    "Of course, what I've done above is only a very rough set of analyses but still enough for me to get going on targetting individuals who are more likely to be able to help me in my quest to raise data awareness in the organisation. But if there were more hours in the day and I had access to other data, I might be able to do even more targetted campaigns. Here are some examples.\n",
    "\n",
    "* I could use Yammer data to craft better messages to individuals, e.g. if I knew a staff member was interested in Education, I might talk to them about adaptive learning and inferring learner cognitive models.\n",
    "* I could use email traffic data or meeting participation data to get a more accurate idea of people's interactions with each other since line management and official team membership are not always the most representative measures of links between people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why I'm telling you about this - two messages to take home\n",
    "\n",
    "* A dataset that is originally used for one purpose (in this case drawing the organisational chart) can be used for many others (in this case identifying promising individuals to target).\n",
    "* You can squeeze a lot of insight out of a small amount of simple data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some things to read\n",
    "* A paper providing a glossary of network terms: https://jech.bmj.com/content/58/12/971\n",
    "* A very comprehensive list of resources for those wishing to implement their own analyses: https://github.com/briatte/awesome-network-analysis\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
