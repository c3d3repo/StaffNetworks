{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using network analysis to efficiently spread data awareness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently heard the wonderful story of how last year, Marks & Spencer launched a data academy to train staff across all parts of the business in data science - HR, Finance, IT, Sales and Operations, Logistics... After an intensive 18-month in-work data skills programme, these staff became data ambassadors for their business areas and local teams so that the effect could spread through the staff network. While it is unlikely that everyone at M&S will become a fully fledged data scientist overnight, the organisation as a whole is now far more data-oriented. For example, HR analyse data to identify staff who might be thinking of leaving; Sales, Operations and Logistics use data to work out how to reduce costs and streamline customer delivery. Importantly, staff ask questions in a data-oriented way and seek to support their decisions with evidence.\n",
    "\n",
    "Inspired by this, I have as one of my ambitions to make my organisation data aware. I don't mean just have awesome data science teams developing cool new products and services (although I hope we will do this too), but rather have everyone in the organisation feel comfortable asking for data to make the best-informed decisions they can.\n",
    "\n",
    "Being new to the organisation though, I was wondering how I might go about doing this. During my first month, my line manager introduced me to several key individuals who were invested in data in some way, either because they were trying to develop data-driven products and services, or because they were using data analyses to make decisions. Through these individuals, I got to know more and more people who had a love for data. I started to compile a list of these data fans and ponddered how quickly we might be able to spread this awareness through the organisation.\n",
    "\n",
    "I decided to get hold of the data behind the organisational chart with all staff's job titles, departments, line managers, functions, etc. so that I could get a feel for the organisation's structure and staff's interests. Then I ran some simple network analyses to help me spread data awareness across the organisation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'anon_staffdata.csv'\n",
    "allstaffdata = pd.read_csv(fname, encoding = \"ISO-8859-1\")\n",
    "colTypes = {'ID': str, 'Department': str, 'Manager': str, 'Location': str, 'DataFan': str}\n",
    "\n",
    "allstaffdata = pd.read_csv(fname, encoding = \"ISO-8859-1\", dtype = colTypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstaffdata.columns\n",
    "allstaffdata.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the data staff?\n",
    "* Which departments?\n",
    "* Which company locations?\n",
    "* Which teams (indicated by line managers)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "staffdata = allstaffdata\n",
    "\n",
    "datafans = staffdata[staffdata['DataFan']=='yes']\n",
    "#List of departments covered by data fans\n",
    "DFDepartments = np.unique(datafans[['Department']])\n",
    "Departments = np.unique(staffdata[['Department']])\n",
    "#List of locations covered by data fans\n",
    "DFLocations = np.unique(datafans[['Location']])\n",
    "Locations = np.unique(staffdata[['Location']])\n",
    "#List of data fan line managers\n",
    "DFManagers = np.unique(datafans[['Manager']])\n",
    "Managers = np.unique(staffdata[['Manager']])\n",
    "\n",
    "\n",
    "#Coverage of data fans:\n",
    "print('#Departments covered by data fans: {} out of {}'.format(len(DFDepartments), len(Departments)))\n",
    "print(DFDepartments)\n",
    "print('#Locations covered by data fans: {} out of {}'.format(len(DFLocations), len(Locations)))\n",
    "print(DFLocations)\n",
    "print('#Managers covered by data fans: {} out of {}'.format(len(DFManagers), len(Managers)))\n",
    "print(DFManagers)\n",
    "\n",
    "#Identify more susceptible staff members in terms of sharing the same departments, locations or teams as existing fans.\n",
    "staffdata['PotentialDepartmentDataFan'] = np.where(staffdata['Department'].isin(DFDepartments), 'yes', 'no')\n",
    "staffdata['PotentialLocationDataFan'] = np.where(staffdata['Location'].isin(DFLocations), 'yes', 'no')\n",
    "staffdata['PotentialManagerDataFan'] = np.where(staffdata['Manager'].isin(DFManagers), 'yes', 'no')\n",
    "\n",
    "staffdata[staffdata['ID'].isin(datafans)]['PotentialLocationDataFan'] = 'yes'\n",
    "staffdata[staffdata['ID'].isin(datafans)]['PotentialDepartmentDataFan'] = 'yes'\n",
    "staffdata[staffdata['ID'].isin(datafans)]['PotentialManagerDataFan'] = 'yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Data fans in the staff network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.convert_matrix.from_pandas_edgelist(staffdata, source='Manager', target='ID', \n",
    "                                           create_using=nx.DiGraph)\n",
    "edges = pd.DataFrame({'target' : staffdata['ID'],\n",
    "                      'source' : staffdata['Manager']})\n",
    "\n",
    "nodes = pd.DataFrame({'node' : staffdata['ID'],\n",
    "                      'name' : staffdata['ID'],\n",
    "                      'Department' : staffdata['Department'],\n",
    "                      'Manager': staffdata['Manager'],\n",
    "                      'Location' : staffdata['Location'],\n",
    "                      'DataFan': staffdata['DataFan'],\n",
    "                     'PotentialDepartmentDataFan': staffdata['PotentialDepartmentDataFan'],\n",
    "                     'PotentialLocationDataFan': staffdata['PotentialLocationDataFan'],\n",
    "                     'PotentialManagerDataFan': staffdata['PotentialManagerDataFan']})\n",
    "d = nx.degree(G)\n",
    "c = nx.degree_centrality(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#Staff in d: {}'.format(len(d)))\n",
    "print('#Staff in c: {}'.format(len(c)))\n",
    "\n",
    "print('Total #Staff: {}'.format(staffdata.shape[0]))\n",
    "\n",
    "\n",
    "degreesdict = {name:degree for name, degree in d}\n",
    "\n",
    "degrees = pd.DataFrame.from_dict(degreesdict, orient='index')\n",
    "centralities = pd.DataFrame.from_dict(c, orient='index')\n",
    "degrees.columns = ['Degree']\n",
    "centralities.columns = ['DegreeCentrality']\n",
    "print(degrees.head())\n",
    "print(centralities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join degrees data to other data\n",
    "staffdata = staffdata.merge(degrees, left_on='ID', right_on=degrees.index)\n",
    "staffdata = staffdata.merge(centralities, left_on='ID', right_on=degrees.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetricHist(df, colname='Degree'):\n",
    "    \n",
    "    data = [go.Histogram(x=df[colname])]\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(\n",
    "            #type='log',\n",
    "            autorange=True\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            #type='log',\n",
    "            autorange=True\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMetricHist(staffdata, 'Degree')\n",
    "plotMetricHist(staffdata, 'DegreeCentrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staffdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drawnetwork(staffdata=staffdata, field='DataFan', d=d, dthreshold=2, sizefield='Degree', sizemultiplier=3, G=G):\n",
    "    \n",
    "    #Formatting settings\n",
    "    #Set colour mappings to field    \n",
    "    flist = staffdata[field].unique()\n",
    "    numcolours = len(flist)\n",
    "    colours = sns.color_palette(\"hls\", numcolours)\n",
    "    colourmappings = dict(zip(flist, colours))\n",
    "    \n",
    "    #Filtering by degree\n",
    "    #Remove nodes with degree (d) below threshold (dthreshold)\n",
    "    selected_nodes = [n for n in nodes.name if d[n] > dthreshold]\n",
    "    plotgraph = G.subgraph(selected_nodes)\n",
    "    \n",
    "    # Set node positions\n",
    "    pos = nx.spring_layout(plotgraph, seed=0)\n",
    "    for node in plotgraph.nodes():\n",
    "        plotgraph.node[node]['pos']= pos[node]\n",
    "        \n",
    "    # Set other node attributes\n",
    "    excluded = []\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    textlist = []\n",
    "    sizelist = []\n",
    "    namelist = []\n",
    "    colourlist = []\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for node in plotgraph.nodes():\n",
    "       \n",
    "    \n",
    "        try:\n",
    "            \n",
    "        \n",
    "            f = nodes[nodes['name']==node][field].values[0]\n",
    "        \n",
    "            x, y = plotgraph.node[node]['pos']\n",
    "            xlist.append(x)\n",
    "            ylist.append(y)\n",
    "            \n",
    "            ## Add node labels for hover over text\n",
    "            text = node + ' <br>#connections: ' + str(d[node])\n",
    "            textlist.append(text)\n",
    "            \n",
    "            ## Size the node depending on sizefield and sizemultiplier\n",
    "            size = staffdata[staffdata['ID']==node][sizefield].values[0]\n",
    "            sizelist.append(size * sizemultiplier)\n",
    "            \n",
    "            ## Map the colours to the nodes depending on the field values\n",
    "            fcolour = 'rgba({}, {}, {}, {})'.format(colourmappings[f][0], colourmappings[f][1], colourmappings[f][2], .8)    \n",
    "            colourlist.append(fcolour)\n",
    "    \n",
    "        except:\n",
    "            excluded.append(node)\n",
    "        \n",
    "    print('Number of nodes excluded because {} not given: {}\\n'.format(field, len(excluded)))\n",
    "    \n",
    "\n",
    "    ## Create the visualisation\n",
    "    xlistedge =[]\n",
    "    ylistedge = []\n",
    "    \n",
    "    for edge in plotgraph.edges():\n",
    "        x0, y0 = plotgraph.node[edge[0]]['pos']\n",
    "        x1, y1 = plotgraph.node[edge[1]]['pos']\n",
    "        xlistedge += [x0, x1, None]\n",
    "        ylistedge += [y0, y1, None]        \n",
    "        \n",
    "    # Create edge trace:\n",
    "    edge_trace = go.Scatter(x = xlistedge, y = ylistedge, text = textlist,\n",
    "                    line = go.scatter.Line(width = 0.5, color = '#888'),\n",
    "                    mode = 'lines', hoverinfo = 'none')\n",
    "    \n",
    "    # Create node trace:\n",
    "    node_trace = go.Scatter(x = xlist, y = ylist, text = textlist, mode = 'markers',\n",
    "                    hoverinfo='text',\n",
    "                    marker = go.scatter.Marker(\n",
    "                    color = colourlist,\n",
    "                    size = sizelist,\n",
    "                    line = dict(color='rgb(50,50,50)', width=0.5)))\n",
    "\n",
    "\n",
    "    data=[node_trace, edge_trace]\n",
    "    layout = go.Layout(title=field, \n",
    "                   showlegend=False, \n",
    "                   xaxis=dict(\n",
    "                   autorange=True,\n",
    "                   showgrid=False,\n",
    "                   zeroline=False,\n",
    "                   showline=False,\n",
    "                   ticks='',\n",
    "                   showticklabels=False),\n",
    "            yaxis=dict(\n",
    "                autorange=True,\n",
    "                showgrid=False,\n",
    "                zeroline=False,\n",
    "                showline=False,\n",
    "                ticks='',\n",
    "                showticklabels=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig, filename='Staff network')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawnetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many disconnected networks are there (in terms of the management structure)?\n",
    "It is useful to know how many disconnected networks there are so that 'islands' can be targeted separately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = list(nx.weakly_connected_component_subgraphs(G))\n",
    "print('#Distinct staff networks: {}\\n'.format(len(subgraphs)))\n",
    "subgraphsizes = [nx.number_of_nodes(subgraphs[i]) for i in range(0, len(subgraphs))]\n",
    "print(subgraphsizes)\n",
    "\n",
    "# Draw the two largest subgraphs\n",
    "drawnetwork(field='DataFan', G=subgraphs[0])\n",
    "drawnetwork(field='DataFan', G=subgraphs[1], dthreshold=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although in terms of management structure there are 44 disconnected subnetworks in the staff network, this does not necessarily mean that these truly represent isolated groups of staff, only that formally speaking, they are not connected to each other via management. The vast majority of staff belong to the larest component (containing 3092, with the next larest only containing 22, see output)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Who should I target next?\n",
    "There is no one correct answer to this, and it is a topic that is much discussed and contested in Marketing,  Communications and Sales. \n",
    "\n",
    "Some strategies are:\n",
    "* Finding nodes in the network that already have neighours or nodes in close proximity that are 'converted'. In this case, I might look for individuals who are in the same team (line-managed by the same people), same country, and/or same business unit. \n",
    "* Finding nodes in the network that are most 'influential'. In this case, I might look for individuals who line manage a lot of people or who have line managers or subordinates who belong to a large number of business units or span many geographical locations.\n",
    "\n",
    "I could also create a metric that combines both of the above and target the ones who score most highly. By doing this, I am choosing individuals who are both more likely to be receptive to data awareness and who are able to raise awareness in a greater number of other individuals.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawnetwork(staffdata=staffdata, field='PotentialDepartmentDataFan')\n",
    "drawnetwork(staffdata=staffdata, field='PotentialLocationDataFan')\n",
    "drawnetwork(staffdata=staffdata, field='PotentialManagerDataFan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top x most connected individuals\n",
    "numtop = 20\n",
    "sortdegrees = staffdata.sort_values(by='Degree', ascending=False)\n",
    "print(sortdegrees.head(numtop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If only I had more data...\n",
    "\n",
    "Of course, what I've done above is only a very rough set of analyses but still enough for me to get going on targetting individuals who are more likely to be able to help me in my quest to raise data awareness in the organisation. But if there were more hours in the day and I had access to other data, I might be able to do even more targetted campaigns. Here are some examples.\n",
    "\n",
    "* I could use Yammer data to craft better messages to individuals, e.g. if I knew a staff member was interested in Education, I might talk to them about adaptive learning and inferring learner cognitive models.\n",
    "* I could use email traffic data or meeting participation data to get a more accurate idea of people's interactions with each other since line management and official team membership are not always the most representative measures of links between people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why I'm telling you about this - two messages to take home\n",
    "\n",
    "* A dataset that is originally used for one purpose (in this case drawing the organisational chart) can be used for many others (in this case identifying promising individuals to target).\n",
    "* You can squeeze a lot of insight out of a small amount of simple data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some things to read\n",
    "* https://plot.ly/python/igraph-networkx-comparison/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
